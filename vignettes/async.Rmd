---
title: "Asynchronous Requests (advanced)"
author: "Jordan Sicherman"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Asynchronous Requests (advanced)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, include = FALSE}
# Don't build this whole thing if it's just for a test. Too long running/taxing on Gemma
# if(Sys.getenv('RMD_BUILD') != 1)
#   knitr::knit_exit()

# Prevent certificate issues for GitHub actions
options(gemma.SSL = FALSE)

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r, message = FALSE}
library(gemmaAPI)
library(dplyr)
library(data.table)
library(memoise)
library(microbenchmark)
```

For very large queries, you can parallelize the requests by using asynchronous requests.

The basic idea is that asynchronous workers can be embedded inside of otherwise synchronous R code by use of a [`synchronise`](https://pavlidislab.github.io/Gemma-API/reference/synchronise.html) block. Inside this, async requests can be made and the main thread will only block while the synchronise block is being requested.

This is made more obvious by example. Take the previous instance where we wanted to fetch annotations for two datasets, `GSE2018` and `GSE25136`. If we want to run API queries asynchronously, we only need to: 1. Embed our requests inside a `synchronise` block 2. Set `async = TRUE` in our requests

We'll build back up to multiple queries, but starting with a single query, the difference is trivial to see.

```{r}
synchronise({
  getDatasetAnnotations('GSE35974', async = TRUE)
}) %>% glimpse()
```

With multiple queries, there's one additional thing we need to do and that is to actually "unpack" our asynchronous results. We have a few options for this ([`when_all`](https://pavlidislab.github.io/Gemma-API/reference/when_all.html), [`when_any`](https://pavlidislab.github.io/Gemma-API/reference/when_some.html), or [`when_some`](https://pavlidislab.github.io/Gemma-API/reference/when_some.html)), but typically we'll just want to receive all the results and thus use `when_all`.

```{r}
synchronise({
  # Make the queries
  res <- lapply(c('GSE35974', 'GSE12649'), function(dataset) {
    getDatasetAnnotations(dataset, async = TRUE)
  })
  
  # Only complete this synchronise block when all queries are finished
  when_all(.list = res)
}) %>% rbindlist %>% glimpse()
```

Finally, we'll introduce one last thing you can do with asynchronous results and that is the deferred chain, `$then`. As we've discussed, the result of a Gemma API query with `async = T` is a deferred value. However, it's still possible to work with them when they become available by specifying code to run when that happens. This is particularly useful when you want to compose information from multiple endpoints.

```{r async}
synchronise({
  # First, get datasets with more than 100 samples. We'll do this synchronously since we need identifiers to continue
  datasets <- getDatasets(filter = 'numberOfSamples > 100', limit = 10)
  
  # Loop over dataset identifiers that we fetched and get differential expression analyses.
  res <- lapply(datasets$ee.ID, function(dataset) {
    # Get the DEA asynchronously and when it becomes available, run a function on the result
    getDatasetDEA(dataset, async = TRUE)$then(function(response) {
      # Now that we have a result ID, we can get differential expression results for these analyses
      diffEx <- lapply(unique(response$result.ID), function(diffExSet) {
        # Make all these requests asynchronously and add the diffExSet when we receive a response
        getDatasetDE(dataset, diffExSet = diffExSet, async = TRUE)$then(function(response) {
          response[, diffExSet := diffExSet]
        })
      })
      
      # When all of these results become available, bind them together for return
      when_all(.list = diffEx)$then(function(results) rbindlist(results))
    })
  })
  
  # Only complete this synchronise block when all queries are finished
  when_all(.list = res)
}) %>% rbindlist %>% glimpse()
```

Although this may look intimidating at first, it's a very powerful way to rapidly make batch queries.

#### Benchmark

For completeness, we'll provide a small benchmark to hopefully convince you that asynchronous programming is worth learning. Both of these functions do the same as the above (although one was rewritten to do it synchronously).

```{r async-benchmark, eval=FALSE}
# First, get datasets with more than 100 samples. We'll do this synchronously since we need identifiers to continue
datasets <- getDatasets(filter = 'numberOfSamples > 100', limit = 10)

asyncBenchmark <- function() {
  synchronise({
    # Loop over dataset identifiers that we fetched and get differential expression analyses.
    res <- lapply(datasets$ee.ID, function(dataset) {
      # Get the DEA asynchronously and when it becomes available, run a function on the result
      getDatasetDEA(dataset, async = TRUE)$then(function(response) {
        # Now that we have a result ID, we can get differential expression results for these analyses
        diffEx <- lapply(unique(response$result.ID), function(diffExSet) {
          # Make all these requests asynchronously and add the diffExSet when we receive a response
          getDatasetDE(dataset, diffExSet = diffExSet, async = TRUE)$then(function(response) {
            response[, diffExSet := diffExSet]
          })
        })
        
        # When all of these results become available, bind them together for return
        when_all(.list = diffEx)$then(function(results) rbindlist(results))
      })
    })
    
    # Only complete this synchronise block when all queries are finished
    when_all(.list = res)
  }) %>% rbindlist
}

syncBenchmark <- function() {
  # Loop over dataset identifiers that we fetched and get differential expression analyses.
  lapply(datasets$ee.ID, function(dataset) {
    # Get the DEA synchronously
    response <- getDatasetDEA(dataset)
    # Now that we have a result ID, we can get differential expression results for these analyses
    lapply(unique(response$result.ID), function(diffExSet) {
      # Make all these requests synchronously and add the diffExSet
      getDatasetDE(dataset, diffExSet = diffExSet)[, diffExSet := diffExSet]
    }) %>% rbindlist
  }) %>% rbindlist
}

knitr::kable(summary(microbenchmark(asyncBenchmark(), syncBenchmark(), times = 5), unit = 's'))
```

```{r, echo = FALSE}
knitr::kable(readRDS("benchmarkTable.rds"))
```


As you can see, the asynchronous method is much faster (about 6x), even on this small test. For larger queries, the gains are even larger.
